epoch,train_loss,val_loss,learning_rate
1,0.23820148775935174,0.1656143556222739,9.5e-05
2,0.14534448181390763,0.1368889182215304,9.025e-05
3,0.1351293134355545,0.1257361879529398,8.573749999999999e-05
4,0.12872611045002938,0.12135929208429878,8.145062499999998e-05
5,0.12450677819013596,0.11928094639573865,7.737809374999998e-05
6,0.12015251175165176,0.11854379232544118,7.350918906249998e-05
7,0.1172343611061573,0.11479475518779071,6.983372960937497e-05
8,0.11717748506069184,0.1184726385947536,6.634204312890622e-05
9,0.11301336899876595,0.11728436747551574,6.30249409724609e-05
10,0.1108270855653286,0.1135474240116756,5.987369392383786e-05
11,0.10924970056414604,0.11477664025390849,5.688000922764596e-05
12,0.10757880996704101,0.11255862660077222,5.4036008766263664e-05
13,0.10662833647847175,0.1124490003966157,5.133420832795048e-05
14,0.10605516751229763,0.10671293859362907,4.876749791155295e-05
15,0.10457936028242111,0.10923290863404493,4.6329123015975305e-05
16,0.10399127827823162,0.10897909990890557,4.4012666865176535e-05
17,0.10330181875705718,0.10184924666533994,4.181203352191771e-05
18,0.10265024250984192,0.10461100440024568,3.972143184582182e-05
19,0.10196707298517227,0.10672788856470067,3.7735360253530726e-05
20,0.10114380263447761,0.10625008587032328,3.584859224085419e-05
